{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fruits 360\n",
    "\n",
    "This uses the weight trained in 'fruits.py' to predict the images in the folder fruits/test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import keras.preprocessing.image\n",
    "\n",
    "\n",
    "def no_warn():\n",
    "    import warnings\n",
    "\n",
    "    def fxn():\n",
    "        warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        # Cause all warnings to always be triggered.\n",
    "        warnings.simplefilter(\"always\")\n",
    "        # Trigger a warning.\n",
    "        fxn()\n",
    "        # Verify some things\n",
    "        assert len(w) == 1\n",
    "        assert issubclass(w[-1].category, DeprecationWarning)\n",
    "        assert \"deprecated\" in str(w[-1].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 22:33:40.833826: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-13 22:33:40.833852: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "no_warn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Weight into the model (Weight is a h5 file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 22:33:44.081522: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-13 22:33:44.081569: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-13 22:33:44.081622: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bee): /proc/driver/nvidia/version does not exist\n",
      "2022-04-13 22:33:44.082150: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('Fruits_360.h5')\n",
    "no_warn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Layout of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 96, 96, 16)        1216      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 48, 48, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 48, 48, 16)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 44, 44, 32)        12832     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 22, 22, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 22, 22, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 18, 18, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 9, 9, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 5, 5, 128)         204928    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 2, 2, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 70)                17990     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,075,942\n",
      "Trainable params: 1,075,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class to predict the images, you only need to call the function read_images to read the iamges, and then the predict funciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class Fruit:\n",
    "    \n",
    "    def __init__(self, img_dir = ''):\n",
    "        self.img_dir = img_dir\n",
    "        self.cnt = 0\n",
    "        self.batch_holder = None\n",
    "        self.model = load_model('Fruits_360.h5')\n",
    "        self.Label_dict = labels =  {'Apple Braeburn': 0,\n",
    "             'Apple Golden': 1,\n",
    "             'Apple Granny Smith': 2,\n",
    "             'Apple Red': 3,\n",
    "             'Apricot': 4,\n",
    "             'Avocado': 5,\n",
    "             'Avocado ripe': 6,\n",
    "             'Banana': 7,\n",
    "             'Banana Lady Finger': 8,\n",
    "             'Banana Red': 9,\n",
    "             'Cactus fruit': 10,\n",
    "             'Cantaloupe 1': 11,\n",
    "             'Cantaloupe 2': 12,\n",
    "             'Carambula': 13,\n",
    "             'Cherry 1': 14,\n",
    "             'Cherry Wax Black': 15,\n",
    "             'Cherry Wax Red': 16,\n",
    "             'Cherry Wax Yellow': 17,\n",
    "             'Chestnut': 18,\n",
    "             'Clementine': 19,\n",
    "             'Cocos': 20,\n",
    "             'Dates': 21,\n",
    "             'Grape Blue': 22,\n",
    "             'Grape Pink': 23,\n",
    "             'Grape White': 24,\n",
    "             'Grapefruit Pink': 25,\n",
    "             'Grapefruit White': 26,\n",
    "             'Guava': 27,\n",
    "             'Hazelnut': 28,\n",
    "             'Huckleberry': 29,\n",
    "             'Kaki': 30,\n",
    "             'Kiwi': 31,\n",
    "             'Kumquats': 32,\n",
    "             'Lemon': 33,\n",
    "             'Lemon Meyer': 34,\n",
    "             'Limes': 35,\n",
    "             'Lychee': 36,\n",
    "             'Mandarine': 37,\n",
    "             'Mango': 38,\n",
    "             'Mangostan': 39,\n",
    "             'Melon Piel de Sapo': 40,\n",
    "             'Mulberry': 41,\n",
    "             'Nectarine': 42,\n",
    "             'Orange': 43,\n",
    "             'Papaya': 44,\n",
    "             'Passion Fruit': 45,\n",
    "             'Peach': 46,\n",
    "             'Peach 2': 47,\n",
    "             'Peach Flat': 48,\n",
    "             'Pear': 49,\n",
    "             'Pear Kaiser': 50,\n",
    "             'Pineapple': 51,\n",
    "             'Pineapple Mini': 52,\n",
    "             'Pitahaya Red': 53,\n",
    "             'Plum': 54,\n",
    "             'Plum 2': 55,\n",
    "             'Plum 3': 56,\n",
    "             'Pomegranate': 57,\n",
    "             'Pomelo Sweetie': 58,\n",
    "             'Rambutan': 59,\n",
    "             'Raspberry': 60,\n",
    "             'Redcurrant': 61,\n",
    "             'Strawberry': 62,\n",
    "             'Strawberry Wedge': 63,\n",
    "             'Tomato 1': 64,\n",
    "             'Tomato 2': 65,\n",
    "             'Tomato 4': 66,\n",
    "             'Tomato Cherry Red': 67,\n",
    "             'Tomato Maroon': 68,\n",
    "             'Walnut': 69}\n",
    "        self.label = list(self.Label_dict.keys())\n",
    "    \n",
    "    def read_images(self):\n",
    "        self.cnt = len(os.listdir(self.img_dir))\n",
    "        self.batch_holder = np.zeros((self.cnt, 100, 100, 3))\n",
    "        for i,img in enumerate(os.listdir(self.img_dir)):\n",
    "            img = image.load_img(os.path.join(self.img_dir,img), target_size=(100, 100))\n",
    "            self.batch_holder[i, :] = img\n",
    "        return self.batch_holder\n",
    "    \n",
    "    def predict(self):\n",
    "        fig = plt.figure(figsize=(20, 20))\n",
    "        for i,img in enumerate(self.batch_holder):\n",
    "            fig.add_subplot(5, 5, i+1)\n",
    "            result=self.model.predict(self.batch_holder)\n",
    "            result_classes = result.argmax(axis=-1)\n",
    "            plt.title(self.label[result_classes[i]])\n",
    "            plt.tick_params(\n",
    "                axis='both',        \n",
    "                which='both',      \n",
    "                bottom=False,      \n",
    "                top=False,         \n",
    "                labelbottom=False,\n",
    "                labelleft=False)\n",
    "            plt.imshow(img/256.)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class takes a parameter -> location of  images that needs to be predicted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obj = Fruit('fruits//test_images//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "obj = Fruit('data/fruits/new_test_images')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.preprocessing.image' has no attribute 'load_img'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_images\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m obj\u001B[38;5;241m.\u001B[39mpredict()\n",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36mFruit.read_images\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_holder \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcnt, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m3\u001B[39m))\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i,img \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(os\u001B[38;5;241m.\u001B[39mlistdir(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_dir)):\n\u001B[0;32m---> 84\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_img\u001B[49m(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_dir,img), target_size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m100\u001B[39m))\n\u001B[1;32m     85\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_holder[i, :] \u001B[38;5;241m=\u001B[39m img\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_holder\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'keras.preprocessing.image' has no attribute 'load_img'"
     ]
    }
   ],
   "source": [
    "obj.read_images()\n",
    "obj.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: Could not find a version that satisfies the requirement keras.preprocessing.image.ImageDataGenerator (from versions: none)\u001B[0m\r\n",
      "\u001B[31mERROR: No matching distribution found for keras.preprocessing.image.ImageDataGenerator\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}